# streamlit run a_mcp_sample.py --server.port=8501
import streamlit as st
import openai
import os
import json
import pandas as pd
from dotenv import load_dotenv
import redis
import psycopg2
import sqlalchemy  # â†è¿½åŠ ï¼šSQLAlchemy ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import requests
from datetime import datetime
import time
import traceback

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# OpenAI APIã‚­ãƒ¼ã®è¨­å®š
openai.api_key = os.getenv('OPENAI_API_KEY')
client = openai.OpenAI()

# Streamlitãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="MCP ã‚µãƒ¼ãƒãƒ¼ ãƒ‡ãƒ¢",
    page_icon="ğŸ¤–",
    layout="wide"
)

st.markdown("<h5>ğŸ¤– MCP ã‚µãƒ¼ãƒãƒ¼ Ã— OpenAI API ãƒ‡ãƒ¢</h5>", unsafe_allow_html=True)
st.markdown("---")

# ã‚«ã‚¹ã‚¿ãƒ CSS
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .status-good {
        color: #28a745;
        font-weight: bold;
    }
    .status-bad {
        color: #dc3545;
        font-weight: bold;
    }
    .info-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        border-left: 4px solid #17a2b8;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§MCPã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ç¢ºèª
st.sidebar.header("ğŸ“Š MCP ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹")


@st.cache_data(ttl=30)  # 30ç§’ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def check_server_status():
    """å„ã‚µãƒ¼ãƒãƒ¼ã®çŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯"""
    status = {}

    # Redis
    try:
        r = redis.Redis(host='localhost', port=6379, db=0, socket_connect_timeout=3)
        r.ping()
        status['Redis'] = "ğŸŸ¢ æ¥ç¶šOK"
    except Exception as e:
        status['Redis'] = f"ğŸ”´ æ¥ç¶šNG ({str(e)[:20]}...)"

    # PostgreSQL
    try:
        conn = psycopg2.connect(
            os.getenv('PG_CONN_STR'),
            connect_timeout=3
        )
        conn.close()
        status['PostgreSQL'] = "ğŸŸ¢ æ¥ç¶šOK"
    except Exception as e:
        status['PostgreSQL'] = f"ğŸ”´ æ¥ç¶šNG ({str(e)[:20]}...)"

    # Elasticsearch
    try:
        response = requests.get('http://localhost:9200/_cluster/health', timeout=3)
        if response.status_code == 200:
            status['Elasticsearch'] = "ğŸŸ¢ æ¥ç¶šOK"
        else:
            status['Elasticsearch'] = f"ğŸ”´ æ¥ç¶šNG (Status: {response.status_code})"
    except Exception as e:
        status['Elasticsearch'] = f"ğŸ”´ æ¥ç¶šNG ({str(e)[:20]}...)"

    # Qdrant
    try:
        response = requests.get('http://localhost:6333/', timeout=3)
        if response.status_code == 200:
            status['Qdrant'] = "ğŸŸ¢ æ¥ç¶šOK"
        else:
            status['Qdrant'] = f"ğŸ”´ æ¥ç¶šNG (Status: {response.status_code})"
    except Exception as e:
        status['Qdrant'] = f"ğŸ”´ æ¥ç¶šNG ({str(e)[:20]}...)"

    return status


# Redis ã‚­ãƒ¼æ•°å–å¾—é–¢æ•°ï¼ˆä¿®æ­£ç‰ˆï¼‰
@st.cache_data(ttl=60)  # 1åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def get_redis_key_count():
    """Redisã‚­ãƒ¼æ•°ã‚’å®‰å…¨ã«å–å¾—"""
    try:
        r = redis.Redis(host='localhost', port=6379, db=0, socket_connect_timeout=3)
        r.ping()
        # scan_iterã‚’ä½¿ç”¨ã—ã¦ãƒ¡ãƒ¢ãƒªåŠ¹ç‡è‰¯ãã‚­ãƒ¼æ•°ã‚’å–å¾—
        count = 0
        for _ in r.scan_iter():
            count += 1
            if count > 1000:  # å®‰å…¨ã®ãŸã‚1000ã§åˆ¶é™
                return f"{count}+"
        return str(count)
    except Exception:
        return "?"


# ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹è¡¨ç¤º
if st.sidebar.button("ğŸ”„ çŠ¶æ…‹æ›´æ–°"):
    st.cache_data.clear()

status = check_server_status()
for server, state in status.items():
    st.sidebar.markdown(f"**{server}**: {state}")

# æ¥ç¶šä¸­ã®ã‚µãƒ¼ãƒãƒ¼æ•°ã‚’è¡¨ç¤º
connected_servers = sum(1 for s in status.values() if "ğŸŸ¢" in s)
st.sidebar.markdown(f"**æ¥ç¶šæ¸ˆã¿**: {connected_servers}/4 ã‚µãƒ¼ãƒãƒ¼")

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
st.sidebar.markdown("---")
st.sidebar.header("âš¡ ã‚¯ã‚¤ãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³")

if st.sidebar.button("ğŸš€ Dockerèµ·å‹•"):
    st.sidebar.code("docker-compose -f docker-compose.mcp-demo.yml up -d")

if st.sidebar.button("ğŸ“Š ãƒ‡ãƒ¼ã‚¿å†æŠ•å…¥"):
    st.sidebar.code("uv run python scripts/setup_test_data.py")

# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
tab1, tab2, tab3, tab4, tab5 = st.tabs([
    "ğŸ” ãƒ‡ãƒ¼ã‚¿ç¢ºèª",
    "ğŸ¤– AI ãƒãƒ£ãƒƒãƒˆ",
    "ğŸ“Š ç›´æ¥ã‚¯ã‚¨ãƒª",
    "ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æ",
    "âš™ï¸ è¨­å®š"
])

with tab1:
    st.write("ğŸ“Š æŠ•å…¥ã•ã‚ŒãŸãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª")

    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦ã‚«ãƒ¼ãƒ‰
    col1, col2, col3, col4 = st.columns(4)

    with col1:
        # Redis ã‚­ãƒ¼æ•°ã‚’ä¿®æ­£ç‰ˆã§å–å¾—
        redis_key_count = get_redis_key_count() if "ğŸŸ¢" in status.get('Redis', '') else "?"
        st.metric(
            label="Redis Keys",
            value=redis_key_count,
            help="Redisã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚­ãƒ¼ã®ç·æ•°"
        )

    with col2:
        st.metric(
            label="PostgreSQL Tables",
            value="3" if "ğŸŸ¢" in status.get('PostgreSQL', '') else "?",
            help="customers, orders, products"
        )

    with col3:
        st.metric(
            label="ES Documents",
            value="5" if "ğŸŸ¢" in status.get('Elasticsearch', '') else "?",
            help="ãƒ–ãƒ­ã‚°è¨˜äº‹ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ•°"
        )

    with col4:
        st.metric(
            label="Qdrant Vectors",
            value="5" if "ğŸŸ¢" in status.get('Qdrant', '') else "?",
            help="å•†å“ãƒ™ã‚¯ãƒˆãƒ«ã®æ•°"
        )

    st.markdown("---")

    # ãƒ‡ãƒ¼ã‚¿è©³ç´°è¡¨ç¤º
    col1, col2 = st.columns(2)

    with col1:
        st.subheader("ğŸ”´ Redis ãƒ‡ãƒ¼ã‚¿")
        if st.button("Redis ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_redis"):
            if "ğŸŸ¢" in status.get('Redis', ''):
                try:
                    r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)
                    with st.spinner("Redisãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿
                        st.write("**ğŸ”‘ ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿:**")
                        session_keys = list(r.scan_iter('session:*'))
                        if session_keys:
                            session_data = []
                            for key in sorted(session_keys):
                                data = r.hgetall(key)
                                data['session_key'] = key
                                session_data.append(data)

                            df_sessions = pd.DataFrame(session_data)
                            st.dataframe(df_sessions, use_container_width=True)
                        else:
                            st.info("ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ‡ãƒ¼ã‚¿
                        st.write("**ğŸ“Š ã‚«ã‚¦ãƒ³ã‚¿ãƒ‡ãƒ¼ã‚¿:**")
                        counter_keys = list(r.scan_iter('counter:*'))
                        if counter_keys:
                            counter_data = {}
                            for key in sorted(counter_keys):
                                counter_data[key.replace('counter:', '')] = r.get(key)

                            # ã‚«ã‚¦ãƒ³ã‚¿ã‚’ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã¨ã—ã¦è¡¨ç¤º
                            counter_cols = st.columns(2)
                            for i, (key, value) in enumerate(counter_data.items()):
                                with counter_cols[i % 2]:
                                    st.metric(key.replace('_', ' ').title(), value)
                        else:
                            st.info("ã‚«ã‚¦ãƒ³ã‚¿ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        # ã‚«ãƒ†ã‚´ãƒªã‚»ãƒƒãƒˆ
                        st.write("**ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒª:**")
                        categories = r.smembers('categories:all')
                        if categories:
                            st.write(", ".join(sorted(categories)))
                        else:
                            st.info("ã‚«ãƒ†ã‚´ãƒªãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        # æ¤œç´¢å±¥æ­´
                        st.write("**ğŸ” æœ€è¿‘ã®æ¤œç´¢å±¥æ­´:**")
                        search_history = r.lrange('search:recent', 0, -1)
                        if search_history:
                            for i, term in enumerate(search_history[:5], 1):
                                st.write(f"{i}. {term}")
                        else:
                            st.info("æ¤œç´¢å±¥æ­´ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
                        st.write("**ğŸ‘¤ ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«:**")
                        profile_keys = list(r.scan_iter('profile:*'))
                        if profile_keys:
                            for key in sorted(profile_keys):
                                profile_data = json.loads(r.get(key))
                                st.json(profile_data)
                        else:
                            st.info("ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                except Exception as e:
                    st.error(f"Redisæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                    st.code(traceback.format_exc())
            else:
                st.warning("Redis ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

    with col2:
        st.subheader("ğŸŸ¦ PostgreSQL ãƒ‡ãƒ¼ã‚¿")
        if st.button("PostgreSQL ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_postgres"):
            if "ğŸŸ¢" in status.get('PostgreSQL', ''):
                try:
                    # SQLAlchemy ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ
                    engine = sqlalchemy.create_engine(os.getenv('PG_CONN_STR'))

                    with st.spinner("PostgreSQLãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                        # é¡§å®¢ãƒ‡ãƒ¼ã‚¿
                        st.write("**ğŸ‘¥ é¡§å®¢ãƒ‡ãƒ¼ã‚¿:**")
                        df_customers = pd.read_sql("SELECT * FROM customers ORDER BY id LIMIT 10", engine)
                        st.dataframe(df_customers, use_container_width=True)

                        # æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿
                        st.write("**ğŸ›’ æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿:**")
                        df_orders = pd.read_sql("""
                                                SELECT o.*, c.name as customer_name
                                                FROM orders o
                                                         JOIN customers c ON o.customer_id = c.id
                                                ORDER BY o.order_date DESC
                                                LIMIT 10
                                                """, engine)
                        st.dataframe(df_orders, use_container_width=True)

                        # å•†å“ãƒ‡ãƒ¼ã‚¿
                        st.write("**ğŸ“¦ å•†å“ãƒ‡ãƒ¼ã‚¿:**")
                        df_products = pd.read_sql("SELECT * FROM products ORDER BY id", engine)
                        st.dataframe(df_products, use_container_width=True)

                        # çµ±è¨ˆæƒ…å ±
                        st.write("**ğŸ“ˆ çµ±è¨ˆæƒ…å ±:**")
                        stats_col1, stats_col2, stats_col3 = st.columns(3)

                        with stats_col1:
                            customer_count = pd.read_sql("SELECT COUNT(*) as count FROM customers", engine).iloc[0][
                                'count']
                            st.metric("ç·é¡§å®¢æ•°", customer_count)

                        with stats_col2:
                            order_count = pd.read_sql("SELECT COUNT(*) as count FROM orders", engine).iloc[0]['count']
                            st.metric("ç·æ³¨æ–‡æ•°", order_count)

                        with stats_col3:
                            total_sales = \
                            pd.read_sql("SELECT SUM(price * quantity) as total FROM orders", engine).iloc[0]['total']
                            st.metric("ç·å£²ä¸Š", f"Â¥{total_sales:,.0f}")

                    # ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‰ã˜ã‚‹
                    engine.dispose()

                except Exception as e:
                    st.error(f"PostgreSQLæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                    st.code(traceback.format_exc())
            else:
                st.warning("PostgreSQL ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

    # Elasticsearch ã¨ Qdrantï¼ˆæ¨ªå¹…ãƒ•ãƒ«æ´»ç”¨ï¼‰
    st.markdown("---")

    st.subheader("ğŸŸ¡ Elasticsearch ãƒ‡ãƒ¼ã‚¿")
    if st.button("Elasticsearch ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_elasticsearch"):
        if "ğŸŸ¢" in status.get('Elasticsearch', ''):
            try:
                with st.spinner("Elasticsearchãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                    response = requests.get(
                        'http://localhost:9200/blog_articles/_search?size=10&sort=published_date:desc')
                    if response.status_code == 200:
                        data = response.json()
                        articles = []
                        for hit in data['hits']['hits']:
                            article = hit['_source']
                            article['_id'] = hit['_id']
                            article['_score'] = hit['_score']
                            articles.append(article)

                        if articles:
                            df_articles = pd.DataFrame(articles)

                            # è¨˜äº‹ã‚’å±•é–‹è¡¨ç¤º
                            for article in articles:
                                with st.expander(f"ğŸ“ {article['title']} (by {article['author']})"):
                                    col_left, col_right = st.columns([2, 1])

                                    with col_left:
                                        st.write(f"**å†…å®¹:** {article['content']}")
                                        st.write(f"**ã‚¿ã‚°:** {', '.join(article['tags'])}")

                                    with col_right:
                                        st.write(f"**ã‚«ãƒ†ã‚´ãƒª:** {article['category']}")
                                        st.write(f"**å…¬é–‹æ—¥:** {article['published_date']}")
                                        st.write(f"**é–²è¦§æ•°:** {article['view_count']:,}")
                        else:
                            st.info("è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                    else:
                        st.error(f"Elasticsearch ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ (Status: {response.status_code})")
            except Exception as e:
                st.error(f"Elasticsearchæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                st.code(traceback.format_exc())
        else:
            st.warning("Elasticsearch ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

    st.subheader("ğŸŸ  Qdrant ãƒ‡ãƒ¼ã‚¿")
    if st.button("Qdrant ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º", key="show_qdrant"):
        if "ğŸŸ¢" in status.get('Qdrant', ''):
            try:
                with st.spinner("Qdrantãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                    # ã¾ãšã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã‚’å–å¾—
                    collections_response = requests.get('http://localhost:6333/collections', timeout=5)

                    if collections_response.status_code == 200:
                        collections_data = collections_response.json()
                        st.write("**ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³:**")
                        st.json(collections_data)

                        collections = collections_data.get('result', {}).get('collections', [])
                        collection_names = [col['name'] for col in collections]

                        if 'product_embeddings' in collection_names:
                            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ãƒ‡ãƒ¼ã‚¿å–å¾—
                            points_response = requests.get(
                                'http://localhost:6333/collections/product_embeddings/points?limit=10')

                            if points_response.status_code == 200:
                                data = points_response.json()
                                if 'result' in data and 'points' in data['result']:
                                    products = []
                                    for point in data['result']['points']:
                                        product = point['payload'].copy()
                                        product['id'] = point['id']
                                        product['vector_size'] = len(point['vector']) if 'vector' in point else 0
                                        products.append(product)

                                    if products:
                                        df_products = pd.DataFrame(products)
                                        st.dataframe(df_products, use_container_width=True)

                                        # å•†å“ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ
                                        st.write("**ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ†å¸ƒ:**")
                                        if 'category' in df_products.columns:
                                            category_counts = df_products['category'].value_counts()
                                            st.bar_chart(category_counts)
                                        else:
                                            st.info("ã‚«ãƒ†ã‚´ãƒªæƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“")
                                    else:
                                        st.info("å•†å“ãƒ™ã‚¯ãƒˆãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                                else:
                                    st.error("Qdrant ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒäºˆæœŸã—ãªã„ã‚‚ã®ã§ã™")
                            else:
                                st.error(f"å•†å“ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ (Status: {points_response.status_code})")
                        else:
                            st.warning("product_embeddingsã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                            st.info("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: " + ", ".join(
                                collection_names) if collection_names else "ãªã—")

                            # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã®ææ¡ˆ
                            st.info("ğŸ’¡ è§£æ±ºæ–¹æ³•: ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
                            st.code("uv run python scripts/setup_test_data.py")
                    else:
                        st.error(
                            f"Qdrant ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ (Status: {collections_response.status_code})")

            except Exception as e:
                st.error(f"Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                st.code(traceback.format_exc())
        else:
            st.warning("Qdrant ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

with tab2:
    st.header("ğŸ¤– AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆMCPçµŒç”±ï¼‰")

    # MCP ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã®ç¢ºèª
    mcp_servers_ready = all(
        "ğŸŸ¢" in status.get(server, '') for server in ['Redis', 'PostgreSQL', 'Elasticsearch', 'Qdrant'])

    if not mcp_servers_ready:
        st.warning("âš ï¸ ä¸€éƒ¨ã®ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„ã€‚")
        st.code("""
# MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•
docker-compose -f docker-compose.mcp-demo.yml up -d redis-mcp postgres-mcp es-mcp qdrant-mcp

# çŠ¶æ…‹ç¢ºèª
docker-compose -f docker-compose.mcp-demo.yml ps
        """)

    # OpenAI API ã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
    if not os.getenv('OPENAI_API_KEY'):
        st.error("ğŸ”‘ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚.envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # ã‚µãƒ³ãƒ—ãƒ«è³ªå•
    st.subheader("ğŸ’¡ ã‚µãƒ³ãƒ—ãƒ«è³ªå•")
    sample_questions = [
        "Redisã«ä¿å­˜ã•ã‚Œã¦ã„ã‚‹ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ã‚’æ•™ãˆã¦",
        "PostgreSQLã®é¡§å®¢ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ±äº¬åœ¨ä½ã®é¡§å®¢ã‚’æ¤œç´¢ã—ã¦",
        "Elasticsearchã§ã€ŒPythonã€ã«é–¢ã™ã‚‹è¨˜äº‹ã‚’æ¤œç´¢ã—ã¦",
        "Qdrantã®å•†å“ãƒ™ã‚¯ãƒˆãƒ«ã‹ã‚‰é¡ä¼¼å•†å“ã‚’è¦‹ã¤ã‘ã¦",
        "ä»Šæ—¥ã®å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦"
    ]

    selected_question = st.selectbox("è³ªå•ã‚’é¸æŠï¼ˆã¾ãŸã¯ä¸‹ã®ãƒãƒ£ãƒƒãƒˆã«ç›´æ¥å…¥åŠ›ï¼‰:",
                                     ["é¸æŠã—ã¦ãã ã•ã„..."] + sample_questions)

    if selected_question != "é¸æŠã—ã¦ãã ã•ã„..." and st.button("ã“ã®è³ªå•ã‚’ä½¿ç”¨"):
        st.session_state.messages.append({"role": "user", "content": selected_question})
        st.rerun()

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´è¡¨ç¤º
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])

    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    if prompt := st.chat_input("ä½•ã‹è³ªå•ã—ã¦ãã ã•ã„"):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.write(prompt)

        # AIå¿œç­”
        with st.chat_message("assistant"):
            response_placeholder = st.empty()

            try:
                with st.spinner("AI ãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                    # å®Ÿéš›ã®OpenAI APIå‘¼ã³å‡ºã—ï¼ˆMCPã‚µãƒ¼ãƒãƒ¼ãªã—ã®å ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
                    if mcp_servers_ready:
                        # å®Ÿéš›ã®MCPå‘¼ã³å‡ºã—ã¯ã“ã“ã«å®Ÿè£…
                        # ç¾åœ¨ã¯ãƒ€ãƒŸãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
                        response_text = f"""
ğŸ¤– **AI Assistant Response**

è³ªå•: "{prompt}"

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨MCPã‚µãƒ¼ãƒãƒ¼ã¨ã®é€£æºæ©Ÿèƒ½ã¯é–‹ç™ºä¸­ã§ã™ã€‚
ä»£ã‚ã‚Šã«ã€åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã«ã¤ã„ã¦èª¬æ˜ã„ãŸã—ã¾ã™ï¼š

**ğŸ“Š åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿:**
- **Redis**: ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ã€ã‚«ã‚¦ãƒ³ã‚¿ã€æ¤œç´¢å±¥æ­´
- **PostgreSQL**: é¡§å®¢æƒ…å ±ã€æ³¨æ–‡ãƒ‡ãƒ¼ã‚¿ã€å•†å“ã‚«ã‚¿ãƒ­ã‚°
- **Elasticsearch**: ãƒ–ãƒ­ã‚°è¨˜äº‹ã€å…¨æ–‡æ¤œç´¢
- **Qdrant**: å•†å“ãƒ™ã‚¯ãƒˆãƒ«ã€æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ 

**ğŸ”§ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:**
1. MCPã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•: `docker-compose -f docker-compose.mcp-demo.yml up -d redis-mcp postgres-mcp`
2. OpenAI Responses API ã‚’ä½¿ç”¨ã—ã¦MCPã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶š
3. è‡ªç„¶è¨€èªã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ“ä½œ

**ğŸ’¡ ç¾åœ¨ã§ãã‚‹ã“ã¨:**
- "ğŸ“Š ç›´æ¥ã‚¯ã‚¨ãƒª" ã‚¿ãƒ–ã§å„ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹
- "ğŸ” ãƒ‡ãƒ¼ã‚¿ç¢ºèª" ã‚¿ãƒ–ã§ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª
                        """
                    else:
                        response_text = f"""
âš ï¸ **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼**

ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ä¸€éƒ¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚

**æ¥ç¶šçŠ¶æ³:**
{chr(10).join([f"- {server}: {state}" for server, state in status.items()])}

**è§£æ±ºæ–¹æ³•:**
1. Docker Composeã§ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’èµ·å‹•:
   ```bash
   docker-compose -f docker-compose.mcp-demo.yml up -d
   ```

2. ã‚µãƒ¼ãƒãƒ¼çŠ¶æ…‹ã‚’ç¢ºèª:
   ```bash
   docker-compose -f docker-compose.mcp-demo.yml ps
   ```

3. ãƒ­ã‚°ã‚’ç¢ºèªï¼ˆã‚¨ãƒ©ãƒ¼ãŒã‚ã‚‹å ´åˆï¼‰:
   ```bash
   docker-compose -f docker-compose.mcp-demo.yml logs
   ```

ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ãŸã‚‰ã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚
                        """

                    # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼é¢¨ã«è¡¨ç¤º
                    full_response = ""
                    for word in response_text.split():
                        full_response += word + " "
                        response_placeholder.markdown(full_response + "â–Œ")
                        time.sleep(0.05)  # ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼åŠ¹æœ

                    response_placeholder.markdown(response_text)
                    st.session_state.messages.append({"role": "assistant", "content": response_text})

            except Exception as e:
                error_msg = f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
                response_placeholder.error(error_msg)
                st.session_state.messages.append({"role": "assistant", "content": error_msg})

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ã‚¯ãƒªã‚¢
    if st.button("ğŸ—‘ï¸ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’ã‚¯ãƒªã‚¢"):
        st.session_state.messages = []
        st.rerun()

with tab3:
    st.header("ğŸ“Š ç›´æ¥ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¯ã‚¨ãƒª")

    query_type = st.selectbox("ã‚¯ã‚¨ãƒªã‚¿ã‚¤ãƒ—ã‚’é¸æŠ",
                              ["Redis", "PostgreSQL", "Elasticsearch", "Qdrant"])

    if query_type == "Redis":
        st.subheader("ğŸ”´ Redis ã‚¯ã‚¨ãƒª")

        # äº‹å‰å®šç¾©ã•ã‚ŒãŸã‚¯ã‚¨ãƒª
        redis_queries = {
            "å…¨ã‚­ãƒ¼è¡¨ç¤º"  : "KEYS *",
            "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°": "KEYS session:*",
            "ã‚«ã‚¦ãƒ³ã‚¿ä¸€è¦§": "KEYS counter:*",
            "ã‚«ãƒ†ã‚´ãƒªè¡¨ç¤º": "SMEMBERS categories:all",
            "æ¤œç´¢å±¥æ­´"    : "LRANGE search:recent 0 -1"
        }

        col1, col2 = st.columns([1, 2])

        with col1:
            st.write("**ã‚¯ã‚¤ãƒƒã‚¯ã‚¯ã‚¨ãƒª:**")
            for name, cmd in redis_queries.items():
                if st.button(name, key=f"redis_{name}"):
                    st.session_state.redis_command = cmd

        with col2:
            redis_command = st.text_input(
                "Redisã‚³ãƒãƒ³ãƒ‰",
                value=getattr(st.session_state, 'redis_command', 'KEYS *'),
                key="redis_input"
            )

        if st.button("å®Ÿè¡Œ", key="redis_exec"):
            if "ğŸŸ¢" in status.get('Redis', ''):
                try:
                    r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

                    # å®‰å…¨ãªã‚³ãƒãƒ³ãƒ‰ã®ã¿ã‚µãƒãƒ¼ãƒˆ
                    cmd_parts = redis_command.strip().split()
                    cmd = cmd_parts[0].upper()

                    if cmd == "KEYS":
                        pattern = cmd_parts[1] if len(cmd_parts) > 1 else "*"
                        result = r.keys(pattern)
                        st.json(sorted(result))
                    elif cmd == "GET":
                        if len(cmd_parts) > 1:
                            key = cmd_parts[1]
                            result = r.get(key)
                            st.code(str(result))
                        else:
                            st.error("GET ã‚³ãƒãƒ³ãƒ‰ã«ã¯ã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
                    elif cmd == "HGETALL":
                        if len(cmd_parts) > 1:
                            key = cmd_parts[1]
                            result = r.hgetall(key)
                            st.json(result)
                        else:
                            st.error("HGETALL ã‚³ãƒãƒ³ãƒ‰ã«ã¯ã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
                    elif cmd == "SMEMBERS":
                        if len(cmd_parts) > 1:
                            key = cmd_parts[1]
                            result = list(r.smembers(key))
                            st.json(sorted(result))
                        else:
                            st.error("SMEMBERS ã‚³ãƒãƒ³ãƒ‰ã«ã¯ã‚­ãƒ¼ã‚’æŒ‡å®šã—ã¦ãã ã•ã„")
                    elif cmd == "LRANGE":
                        if len(cmd_parts) >= 4:
                            key = cmd_parts[1]
                            start = int(cmd_parts[2])
                            stop = int(cmd_parts[3])
                            result = r.lrange(key, start, stop)
                            st.json(result)
                        else:
                            st.error("LRANGE ã‚³ãƒãƒ³ãƒ‰ã®å½¢å¼: LRANGE key start stop")
                    else:
                        st.error(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ã‚³ãƒãƒ³ãƒ‰ã§ã™: {cmd}")
                        st.info("ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹ã‚³ãƒãƒ³ãƒ‰: KEYS, GET, HGETALL, SMEMBERS, LRANGE")

                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("Redis ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

    elif query_type == "PostgreSQL":
        st.subheader("ğŸŸ¦ PostgreSQL ã‚¯ã‚¨ãƒª")

        # äº‹å‰å®šç¾©ã•ã‚ŒãŸã‚¯ã‚¨ãƒª
        pg_queries = {
            "å…¨é¡§å®¢"    : "SELECT * FROM customers ORDER BY id;",
            "æ±äº¬ã®é¡§å®¢": "SELECT * FROM customers WHERE city = 'æ±äº¬';",
            "æœ€æ–°æ³¨æ–‡"  : "SELECT o.*, c.name FROM orders o JOIN customers c ON o.customer_id = c.id ORDER BY o.order_date DESC LIMIT 5;",
            "å£²ä¸Šçµ±è¨ˆ"  : "SELECT product_name, SUM(price * quantity) as total_sales FROM orders GROUP BY product_name ORDER BY total_sales DESC;",
            "å•†å“åœ¨åº«"  : "SELECT name, stock_quantity, price FROM products ORDER BY stock_quantity DESC;"
        }

        col1, col2 = st.columns([1, 2])

        with col1:
            st.write("**ã‚¯ã‚¤ãƒƒã‚¯ã‚¯ã‚¨ãƒª:**")
            for name, sql in pg_queries.items():
                if st.button(name, key=f"pg_{name}"):
                    st.session_state.sql_query = sql

        with col2:
            sql_query = st.text_area(
                "SQLã‚¯ã‚¨ãƒª",
                value=getattr(st.session_state, 'sql_query', 'SELECT * FROM customers LIMIT 5;'),
                height=100,
                key="pg_input"
            )

        if st.button("å®Ÿè¡Œ", key="pg_exec"):
            if "ğŸŸ¢" in status.get('PostgreSQL', ''):
                try:
                    # å®‰å…¨æ€§ã®ãŸã‚ã€SELECTã‚¯ã‚¨ãƒªã®ã¿è¨±å¯
                    if not sql_query.strip().upper().startswith('SELECT'):
                        st.error("å®‰å…¨æ€§ã®ãŸã‚ã€SELECTã‚¯ã‚¨ãƒªã®ã¿å®Ÿè¡Œã§ãã¾ã™")
                    else:
                        # SQLAlchemy ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½¿ç”¨
                        engine = sqlalchemy.create_engine(os.getenv('PG_CONN_STR'))
                        df = pd.read_sql(sql_query, engine)

                        if len(df) > 0:
                            st.dataframe(df, use_container_width=True)

                            # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½
                            csv = df.to_csv(index=False).encode('utf-8-sig')
                            st.download_button(
                                label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                data=csv,
                                file_name=f"query_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                                mime='text/csv'
                            )
                        else:
                            st.info("ã‚¯ã‚¨ãƒªã®çµæœã¯ç©ºã§ã—ãŸ")

                        engine.dispose()

                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("PostgreSQL ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

    elif query_type == "Elasticsearch":
        st.subheader("ğŸŸ¡ Elasticsearch ã‚¯ã‚¨ãƒª")

        search_term = st.text_input("æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰", "Python")
        search_field = st.selectbox("æ¤œç´¢å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰", ["å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰", "title", "content", "category", "author"])

        if st.button("æ¤œç´¢å®Ÿè¡Œ", key="es_exec"):
            if "ğŸŸ¢" in status.get('Elasticsearch', ''):
                try:
                    # æ¤œç´¢ã‚¯ã‚¨ãƒªã®æ§‹ç¯‰
                    if search_field == "å…¨ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰":
                        query = {
                            "query"    : {
                                "multi_match": {
                                    "query" : search_term,
                                    "fields": ["title^2", "content", "category", "author"]
                                }
                            },
                            "highlight": {
                                "fields": {
                                    "title"  : {},
                                    "content": {}
                                }
                            }
                        }
                    else:
                        query = {
                            "query"    : {
                                "match": {
                                    search_field: search_term
                                }
                            },
                            "highlight": {
                                "fields": {
                                    search_field: {}
                                }
                            }
                        }

                    response = requests.post(
                        'http://localhost:9200/blog_articles/_search',
                        json=query,
                        headers={'Content-Type': 'application/json'}
                    )

                    if response.status_code == 200:
                        data = response.json()
                        hits = data['hits']['hits']

                        if hits:
                            st.success(f"ğŸ¯ {len(hits)}ä»¶ã®è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

                            for hit in hits:
                                article = hit['_source']
                                score = hit['_score']

                                with st.expander(f"ğŸ“ {article['title']} (ã‚¹ã‚³ã‚¢: {score:.2f})"):
                                    col1, col2 = st.columns([3, 1])

                                    with col1:
                                        st.write(f"**å†…å®¹:** {article['content']}")

                                        # ãƒã‚¤ãƒ©ã‚¤ãƒˆè¡¨ç¤º
                                        if 'highlight' in hit:
                                            st.write("**ãƒã‚¤ãƒ©ã‚¤ãƒˆ:**")
                                            for field, highlights in hit['highlight'].items():
                                                for highlight in highlights:
                                                    st.markdown(f"â€¢ {highlight}", unsafe_allow_html=True)

                                    with col2:
                                        st.metric("é–²è¦§æ•°", f"{article['view_count']:,}")
                                        st.write(f"**è‘—è€…:** {article['author']}")
                                        st.write(f"**ã‚«ãƒ†ã‚´ãƒª:** {article['category']}")
                                        st.write(f"**å…¬é–‹æ—¥:** {article['published_date']}")
                                        st.write(f"**ã‚¿ã‚°:** {', '.join(article['tags'])}")
                        else:
                            st.info(f"'{search_term}' ã«é–¢ã™ã‚‹è¨˜äº‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    else:
                        st.error(f"æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ (Status: {response.status_code})")

                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("Elasticsearch ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

    elif query_type == "Qdrant":
        st.subheader("ğŸŸ  Qdrant ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢")

        st.info("ğŸ’¡ å®Ÿéš›ã®ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢ã«ã¯åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ãŒå¿…è¦ã§ã™ãŒã€ã“ã“ã§ã¯ãƒ†ã‚¹ãƒˆç”¨ã®æ©Ÿèƒ½ã‚’æä¾›ã—ã¾ã™")

        col1, col2 = st.columns(2)

        with col1:
            search_category = st.selectbox("ã‚«ãƒ†ã‚´ãƒªã§æ¤œç´¢",
                                           ["å…¨ã¦", "ã‚¨ãƒ¬ã‚¯ãƒˆãƒ­ãƒ‹ã‚¯ã‚¹", "ã‚­ãƒƒãƒãƒ³å®¶é›»", "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³", "ã‚¹ãƒãƒ¼ãƒ„"])
            price_range = st.slider("ä¾¡æ ¼å¸¯", 0, 100000, (0, 100000), step=1000)

        with col2:
            limit = st.number_input("å–å¾—ä»¶æ•°", min_value=1, max_value=20, value=5)

        if st.button("æ¤œç´¢å®Ÿè¡Œ", key="qdrant_exec"):
            if "ğŸŸ¢" in status.get('Qdrant', ''):
                try:
                    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶ã®æ§‹ç¯‰
                    filter_conditions = []

                    if search_category != "å…¨ã¦":
                        filter_conditions.append({
                            "key"  : "category",
                            "match": {"value": search_category}
                        })

                    filter_conditions.extend([
                        {"key": "price", "range": {"gte": price_range[0]}},
                        {"key": "price", "range": {"lte": price_range[1]}}
                    ])

                    # æ¤œç´¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                    search_request = {
                        "filter"      : {
                            "must": filter_conditions
                        },
                        "limit"       : limit,
                        "with_payload": True
                    }

                    response = requests.post(
                        'http://localhost:6333/collections/product_embeddings/points/search',
                        json=search_request,
                        headers={'Content-Type': 'application/json'}
                    )

                    if response.status_code == 200:
                        data = response.json()
                        if 'result' in data and data['result']:
                            points = data['result']

                            st.success(f"ğŸ¯ {len(points)}ä»¶ã®å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ")

                            # å•†å“ä¸€è¦§è¡¨ç¤º
                            products = []
                            for point in points:
                                product = point['payload']
                                product['id'] = point['id']
                                if 'score' in point:
                                    product['similarity_score'] = point['score']
                                products.append(product)

                            df_results = pd.DataFrame(products)
                            st.dataframe(df_results, use_container_width=True)

                            # å•†å“è©³ç´°ã‚«ãƒ¼ãƒ‰
                            for product in products:
                                with st.expander(f"ğŸ›ï¸ {product['name']} - Â¥{product['price']:,}"):
                                    col1, col2 = st.columns([2, 1])

                                    with col1:
                                        st.write(f"**èª¬æ˜:** {product['description']}")
                                        st.write(f"**ã‚«ãƒ†ã‚´ãƒª:** {product['category']}")

                                    with col2:
                                        st.metric("ä¾¡æ ¼", f"Â¥{product['price']:,}")
                                        if 'similarity_score' in product:
                                            st.metric("é¡ä¼¼åº¦ã‚¹ã‚³ã‚¢", f"{product['similarity_score']:.3f}")
                        else:
                            st.info("æ¡ä»¶ã«åˆã†å•†å“ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                    else:
                        st.error(f"æ¤œç´¢ã«å¤±æ•—ã—ã¾ã—ãŸ (Status: {response.status_code})")

                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")
            else:
                st.warning("Qdrant ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")

with tab4:
    st.header("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

    if all("ğŸŸ¢" in status.get(server, '') for server in ['PostgreSQL', 'Redis']):
        try:
            # SQLAlchemy ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ
            engine = sqlalchemy.create_engine(os.getenv('PG_CONN_STR'))

            # å£²ä¸Šåˆ†æ
            st.subheader("ğŸ’° å£²ä¸Šåˆ†æ")

            col1, col2, col3 = st.columns(3)

            # ç·å£²ä¸Š
            total_sales = pd.read_sql("SELECT SUM(price * quantity) as total FROM orders", engine).iloc[0]['total']
            with col1:
                st.metric("ç·å£²ä¸Š", f"Â¥{total_sales:,.0f}")

            # å¹³å‡æ³¨æ–‡ä¾¡æ ¼
            avg_order = pd.read_sql("SELECT AVG(price * quantity) as avg FROM orders", engine).iloc[0]['avg']
            with col2:
                st.metric("å¹³å‡æ³¨æ–‡ä¾¡æ ¼", f"Â¥{avg_order:,.0f}")

            # æ³¨æ–‡æ•°
            order_count = pd.read_sql("SELECT COUNT(*) as count FROM orders", engine).iloc[0]['count']
            with col3:
                st.metric("ç·æ³¨æ–‡æ•°", f"{order_count:,}")

            # å•†å“åˆ¥å£²ä¸Š
            st.subheader("ğŸ“Š å•†å“åˆ¥å£²ä¸Š")
            product_sales = pd.read_sql("""
                                        SELECT product_name,
                                               SUM(price * quantity) as total_sales,
                                               COUNT(*)              as order_count
                                        FROM orders
                                        GROUP BY product_name
                                        ORDER BY total_sales DESC
                                        """, engine)

            col1, col2 = st.columns(2)

            with col1:
                st.bar_chart(product_sales.set_index('product_name')['total_sales'])

            with col2:
                st.bar_chart(product_sales.set_index('product_name')['order_count'])

            # é¡§å®¢åˆ†æ
            st.subheader("ğŸ‘¥ é¡§å®¢åˆ†æ")

            customer_stats = pd.read_sql("""
                                         SELECT c.city,
                                                COUNT(c.id)                            as customer_count,
                                                COUNT(o.id)                            as total_orders,
                                                COALESCE(SUM(o.price * o.quantity), 0) as total_spent
                                         FROM customers c
                                                  LEFT JOIN orders o ON c.id = o.customer_id
                                         GROUP BY c.city
                                         ORDER BY total_spent DESC
                                         """, engine)

            col1, col2 = st.columns(2)

            with col1:
                st.write("**éƒ½å¸‚åˆ¥é¡§å®¢æ•°**")
                st.bar_chart(customer_stats.set_index('city')['customer_count'])

            with col2:
                st.write("**éƒ½å¸‚åˆ¥å£²ä¸Š**")
                st.bar_chart(customer_stats.set_index('city')['total_spent'])

            # Redisçµ±è¨ˆ
            st.subheader("ğŸ”´ Redis çµ±è¨ˆ")

            r = redis.Redis(host='localhost', port=6379, db=0, decode_responses=True)

            redis_col1, redis_col2, redis_col3 = st.columns(3)

            with redis_col1:
                active_sessions = len(r.keys('session:*'))
                st.metric("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚»ãƒƒã‚·ãƒ§ãƒ³", active_sessions)

            with redis_col2:
                page_views = r.get('counter:page_views') or 0
                st.metric("ãƒšãƒ¼ã‚¸ãƒ“ãƒ¥ãƒ¼", f"{page_views:,}")

            with redis_col3:
                search_count = r.llen('search:recent')
                st.metric("æ¤œç´¢å±¥æ­´æ•°", search_count)

            # ã‚¨ãƒ³ã‚¸ãƒ³ã‚’é–‰ã˜ã‚‹
            engine.dispose()

        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    else:
        st.warning("ãƒ‡ãƒ¼ã‚¿åˆ†æã«ã¯ PostgreSQL ã¨ Redis ã®æ¥ç¶šãŒå¿…è¦ã§ã™")

with tab5:
    st.header("âš™ï¸ è¨­å®šã¨ãƒ˜ãƒ«ãƒ—")

    # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±
    st.subheader("ğŸ–¥ï¸ ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±")

    col1, col2 = st.columns(2)

    with col1:
        st.write("**ç’°å¢ƒå¤‰æ•°:**")
        env_status = {
            "OPENAI_API_KEY": "è¨­å®šæ¸ˆã¿" if os.getenv('OPENAI_API_KEY') else "âŒ æœªè¨­å®š",
            "REDIS_URL"     : os.getenv('REDIS_URL', 'æœªè¨­å®š'),
            "PG_CONN_STR"   : "è¨­å®šæ¸ˆã¿" if os.getenv('PG_CONN_STR') else "âŒ æœªè¨­å®š",
            "ELASTIC_URL"   : os.getenv('ELASTIC_URL', 'http://localhost:9200'),
            "QDRANT_URL"    : os.getenv('QDRANT_URL', 'http://localhost:6333')
        }

        for key, value in env_status.items():
            if "âŒ" in str(value):
                st.error(f"**{key}**: {value}")
            else:
                st.success(f"**{key}**: {value}")

    with col2:
        st.write("**ã‚µãƒ¼ãƒãƒ¼æ¥ç¶šçŠ¶æ³:**")
        for server, state in status.items():
            if "ğŸŸ¢" in state:
                st.success(f"**{server}**: æ¥ç¶šOK")
            else:
                st.error(f"**{server}**: æ¥ç¶šNG")

    # Docker ã‚³ãƒãƒ³ãƒ‰
    st.subheader("ğŸ³ Docker ç®¡ç†ã‚³ãƒãƒ³ãƒ‰")

    command_tabs = st.tabs(["èµ·å‹•", "åœæ­¢", "ãƒ­ã‚°ç¢ºèª", "ãƒ‡ãƒ¼ã‚¿ãƒªã‚»ãƒƒãƒˆ"])

    with command_tabs[0]:
        st.write("**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èµ·å‹•:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml up -d redis postgres elasticsearch qdrant")

        st.write("**MCPã‚µãƒ¼ãƒãƒ¼èµ·å‹•:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml up -d redis-mcp postgres-mcp es-mcp qdrant-mcp")

        st.write("**å…¨ã‚µãƒ¼ãƒ“ã‚¹èµ·å‹•:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml up -d")

    with command_tabs[1]:
        st.write("**å…¨ã‚µãƒ¼ãƒ“ã‚¹åœæ­¢:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml down")

        st.write("**ãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚‚å‰Šé™¤ï¼‰:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml down -v")

    with command_tabs[2]:
        st.write("**å…¨ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ã‚°:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml logs -f")

        st.write("**ç‰¹å®šã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ­ã‚°:**")
        st.code("docker-compose -f docker-compose.mcp-demo.yml logs -f redis-mcp")

    with command_tabs[3]:
        st.write("**ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å†æŠ•å…¥:**")
        st.code("uv run python scripts/setup_test_data.py")

        st.write("**å®Œå…¨ãƒªã‚»ãƒƒãƒˆ:**")
        st.code("""
# åœæ­¢ã—ã¦ãƒœãƒªãƒ¥ãƒ¼ãƒ å‰Šé™¤  
docker-compose -f docker-compose.mcp-demo.yml down -v

# å†èµ·å‹•
docker-compose -f docker-compose.mcp-demo.yml up -d

# ãƒ‡ãƒ¼ã‚¿å†æŠ•å…¥
uv run python scripts/setup_test_data.py
        """)

    # MCP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæƒ…å ±
    st.subheader("ğŸŒ MCP ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ")

    mcp_endpoints = {
        "Redis MCP"        : "http://localhost:8000/mcp",
        "PostgreSQL MCP"   : "http://localhost:8001/mcp",
        "Elasticsearch MCP": "http://localhost:8002/mcp",
        "Qdrant MCP"       : "http://localhost:8003/mcp"
    }

    st.json(mcp_endpoints)

    # ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
    st.subheader("ğŸ”§ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°")

    with st.expander("â“ ã‚ˆãã‚ã‚‹å•é¡Œã¨è§£æ±ºæ–¹æ³•"):
        st.markdown("""
        **ğŸ”´ Redis æ¥ç¶šã‚¨ãƒ©ãƒ¼**
        - Dockerã‚³ãƒ³ãƒ†ãƒŠãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèª: `docker ps | grep redis`
        - ãƒãƒ¼ãƒˆ6379ãŒä½¿ç”¨ä¸­ã§ãªã„ã‹ç¢ºèª: `lsof -i :6379`

        **ğŸŸ¦ PostgreSQL æ¥ç¶šã‚¨ãƒ©ãƒ¼**
        - èªè¨¼æƒ…å ±ã‚’ç¢ºèª: `testuser/testpass`
        - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚’ç¢ºèª: `docker-compose logs postgres`

        **ğŸŸ¡ Elasticsearch æ¥ç¶šã‚¨ãƒ©ãƒ¼**
        - ãƒ¡ãƒ¢ãƒªä¸è¶³ã®å¯èƒ½æ€§: `docker stats`
        - Java heap sizeè¨­å®šã‚’ç¢ºèª: `ES_JAVA_OPTS=-Xms512m -Xmx512m`

        **ğŸŸ  Qdrant æ¥ç¶šã‚¨ãƒ©ãƒ¼**
        - ã‚³ãƒ³ãƒ†ãƒŠã®èµ·å‹•çŠ¶æ³: `docker-compose ps qdrant`
        - ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: `curl http://localhost:6333/`

        **ğŸ¤– OpenAI API ã‚¨ãƒ©ãƒ¼**
        - APIã‚­ãƒ¼ã®è¨­å®šç¢ºèª: `.env`ãƒ•ã‚¡ã‚¤ãƒ«
        - ã‚¯ã‚©ãƒ¼ã‚¿åˆ¶é™ã®ç¢ºèª: OpenAIãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
        """)

    # ã‚¢ãƒ—ãƒªæƒ…å ±
    st.subheader("â„¹ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±")

    app_info = {
        "ãƒãƒ¼ã‚¸ãƒ§ãƒ³": "1.0.0",
        "ä½œæˆæ—¥"    : "2024-01-15",
        "Python"    : "3.11+",
        "Streamlit" : st.__version__,
        "ä½¿ç”¨æŠ€è¡“"  : ["Docker", "Redis", "PostgreSQL", "Elasticsearch", "Qdrant", "OpenAI API"]
    }

    st.json(app_info)

# ãƒ•ãƒƒã‚¿ãƒ¼
st.markdown("---")
st.markdown("""
<div style="text-align: center; color: #666; padding: 20px;">
    <p><strong>ğŸš€ MCP Demo App</strong> - OpenAI API Ã— MCP ã‚µãƒ¼ãƒãƒ¼é€£æºã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³</p>
    <p>Made with â¤ï¸ using Streamlit</p>
</div>
""", unsafe_allow_html=True)

# streamlit run a_mcp_sample.py --server.port=8501
